{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "from rrc.envs import cube_env, initializers\n",
    "from gym.wrappers import FlattenObservation, FilterObservation\n",
    "\n",
    "from spinup.utils import test_policy\n",
    "from spinup.user_config import DEFAULT_DATA_DIR\n",
    "from xvfbwrapper import Xvfb\n",
    "from rrc.envs.wrappers import PyBulletClearGUIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading from /scr-ssd/ksrini/spinningup/data/2021-06-03_ppo-rrc-diff4_irandom/2021-06-03_12-03-09-ppo-rrc-diff4_irandom_s0/pyt_save/model499.pt.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# env, pol = test_policy.load_policy_and_env('/scr-ssd/ksrini/spinningup/data/2021-06-03_ppo-rrc-acclip/2021-06-03_10-59-54-ppo-rrc-acclip_s0')\n",
    "env, pol = test_policy.load_policy_and_env('/scr-ssd/ksrini/spinningup/data/2021-06-03_ppo-rrc-diff4_irandom/2021-06-03_12-03-09-ppo-rrc-diff4_irandom_s0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "xvfb = Xvfb()\n",
    "xvfb.start()\n",
    "\n",
    "goal_pose = None # {'position': np.array([0,0,0.0325]), 'orientation': np.array([0,0,0,1])}\n",
    "env = cube_env.CubeEnv(goal_pose, 1, initializer=env.initializer, episode_length=500,\n",
    "                       visualization=True, save_mp4=True, save_dir='./videos')\n",
    "env = PyBulletClearGUIWrapper(env)\n",
    "env = FlattenObservation(FilterObservation(env, filter_keys=['observation', 'desired_goal']))\n",
    "obs = env.reset()\n",
    "d = False\n",
    "while not d:\n",
    "    obs, r, d, i = env.step(pol(obs))\n",
    "obs = env.reset()\n",
    "xvfb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  3.2499999e-02, -9.8478017e-07,\n",
       "        -1.3081907e-05, -5.7593757e-01,  8.1749368e-01,  6.4295933e-02,\n",
       "         7.0091151e-02,  1.3454532e-02, -6.0875551e-05,  4.8068559e-05,\n",
       "         4.1382122e-01, -1.4876003e-03, -2.2157433e-03, -1.1878055e-05],\n",
       "       dtype=float32),\n",
       " -0.21716879579162512,\n",
       " False,\n",
       " {'difficulty': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, r, d, i = env.step(pol(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "xvfb = Xvfb()\n",
    "xvfb.start()\n",
    "\n",
    "goal_pose = {'position': np.array([0,0,0.0325]), 'orientation': np.array([0,0,0,1])}\n",
    "env = cube_env.CubeEnv(goal_pose, 1, initializer=initializers.CenteredInitializer(1), episode_length=500,\n",
    "                       visualization=True, save_mp4=True, save_dir='./videos')\n",
    "env = FlattenObservation(FilterObservation(env, filter_keys=['observation', 'desired_goal']))\n",
    "obs = env.reset()\n",
    "d = False\n",
    "while not d:\n",
    "    obs, r, d, i = env.step(pol(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "goal_pose = {'position': np.array([0,0,0.0325]), 'orientation': np.array([0,0,0,1])}\n",
    "env = cube_env.CubeEnv(goal_pose, 1, initializer=initializers.CenteredInitializer(1), episode_length=1000)\n",
    "env = FlattenObservation(FilterObservation(env, filter_keys=['observation', 'desired_goal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import functools\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces import flatten_space\n",
    "from gym.wrappers import Monitor as GymMonitor\n",
    "from gym.wrappers import FilterObservation\n",
    "from rrc.env import initializers, cube_env\n",
    "from rrc.env.reward_fns import *\n",
    "from rrc.env.wrappers import MonitorPyBulletWrapper\n",
    "from rrc.env.termination_fns import stay_close_to_goal\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import CombinedExtractor\n",
    "from stable_baselines3.common.preprocessing import get_flattened_obs_dim, is_image_space\n",
    "from stable_baselines3 import HerReplayBuffer, SAC, TD3, PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "class FlattenGoalObs(ObservationWrapper):\n",
    "    def __init__(self, env, observation_keys):\n",
    "        super().__init__(env)\n",
    "        obs_space = self.env.observation_space\n",
    "        obs_dict = {k: flatten_space(obs_space[k]) for k in observation_keys}\n",
    "        self.observation_space = gym.spaces.Dict(obs_dict)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        n_obs = {}\n",
    "        for k in self.observation_space.spaces:\n",
    "            if isinstance(obs[k], dict):\n",
    "                obs_list = [obs[k][k2] for k2 in self.env.observation_space[k]]\n",
    "                n_obs[k] = np.concatenate(obs_list)\n",
    "            else:\n",
    "                n_obs[k] = obs[k]\n",
    "        return n_obs\n",
    "\n",
    "\n",
    "class ResidualPDWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, Kp=np.eye(3)*np.array([100,100,1]), Kd=1, include_ac=False):\n",
    "        super(ResidualPDWrapper, self).__init__(env)\n",
    "        self.Kp = Kp\n",
    "        self.Kd = Kd\n",
    "        self._obs = self._prev_obs = None\n",
    "        self.include_ac = include_ac\n",
    "        if self.include_ac:\n",
    "            obs_dict = self.env.observation_space.spaces\n",
    "            obs_dict = {k: obs_dict['observation'][k] for k in obs_dict['observation']}\n",
    "            obs_dict['pd_action'] = gym.spaces.Box(low=-np.ones(3), high=np.ones(3))\n",
    "            self.observation_space.spaces['observation'] = obs_dict\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = super(ResidualPDWrapper, self).reset()\n",
    "        self._prev_obs = None\n",
    "        self._obs = obs\n",
    "        if self.include_ac:\n",
    "            obs['observation']['pd_action'] = self.pd_action(self._obs, self._prev_obs)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        action[:3] *= self.env.unwrapped.force_factor\n",
    "        action[3:] *= self.env.unwrapped.torque_factor\n",
    "        pd_action = self.pd_action(self._obs, self._prev_obs)\n",
    "        ac = action + pd_action\n",
    "        self._prev_obs = self._obs\n",
    "        obs, r, d, i = self.env.step(ac)\n",
    "        self._obs = obs\n",
    "        if self.include_ac:\n",
    "            obs['observation']['pd_action'] = self.pd_action(self._obs, self._prev_obs)\n",
    "        return obs, r, d, i\n",
    "    \n",
    "    def pd_action(self, observation, prev_observation):\n",
    "        if observation is None:\n",
    "            return np.zeros(6)\n",
    "        if observation['observation'].get('pd_action') is not None:\n",
    "            return observation['observation']['pd_action']\n",
    "        err = observation['observation']['position']\n",
    "        u = -self.Kp @ err\n",
    "        if prev_observation is None:\n",
    "            return np.concatenate([u, np.zeros(3)], axis=-1)\n",
    "        err_diff = observation['observation']['position'] - prev_observation['observation']['position']\n",
    "        u -= self.Kd * err_diff / self.env.time_step_s\n",
    "        return np.concatenate([u, np.zeros(3)], axis=-1)\n",
    "\n",
    "    \n",
    "class HERCombinedExtractor(CombinedExtractor):\n",
    "    \"\"\"\n",
    "    HERCombinedExtractor is a combined extractor which only extracts pre-specified observation_keys to include in\n",
    "    the observation, while retaining them at the environment level so that they may still be stored in the replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, cnn_output_dim: int = 256, observation_keys: list = []):\n",
    "        # TODO we do not know features-dim here before going over all the items, so put something there. This is dirty!\n",
    "        super(CombinedExtractor, self).__init__(observation_space, features_dim=1)\n",
    "\n",
    "        extractors = {}\n",
    "\n",
    "        total_concat_size = 0\n",
    "        for key in observation_keys:\n",
    "            subspace = observation_space.spaces[key]\n",
    "            # The observation key is a vector, flatten it if needed\n",
    "            extractors[key] = nn.Flatten()\n",
    "            total_concat_size += get_flattened_obs_dim(subspace)\n",
    "\n",
    "        self.extractors = nn.ModuleDict(extractors)\n",
    "\n",
    "        # Update the features dim manually\n",
    "        self._features_dim = total_concat_size\n",
    "\n",
    "\n",
    "def make_sac_model(ep_len, lr, exp_dir=None, env=None, use_goal=True,\n",
    "               use_sde=False):\n",
    "    if use_goal:\n",
    "        obs_keys = ['desired_goal', 'observation']\n",
    "    else:\n",
    "        obs_keys = ['observation']\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "                    log_std_init=-3,\n",
    "                    features_extractor_class=HERCombinedExtractor,\n",
    "                    features_extractor_kwargs=dict(observation_keys=obs_keys))\n",
    "    if use_sde:\n",
    "        sde_kwargs = dict(\n",
    "                use_sde=True,\n",
    "                use_sde_at_warmup=True,\n",
    "                sde_sample_freq=64)\n",
    "    else:\n",
    "        sde_kwargs = {}\n",
    "\n",
    "    rb_kwargs = dict(\n",
    "                    n_sampled_goal=4,\n",
    "                    goal_selection_strategy='future',\n",
    "                    online_sampling=False,\n",
    "                    max_episode_length=ep_len)\n",
    "\n",
    "    model = SAC('MultiInputPolicy', env,\n",
    "                # tensorboard_log=exp_dir,\n",
    "                replay_buffer_class=HerReplayBuffer,\n",
    "                # Parameters for HER\n",
    "                replay_buffer_kwargs=rb_kwargs,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "                verbose=1, buffer_size=int(1e6),\n",
    "                learning_starts=1500,\n",
    "                learning_rate=lr,\n",
    "                gamma=0.99, batch_size=256, **sde_kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_ppo_model(ep_len, lr, exp_dir=None, env=None, use_goal=True,\n",
    "                   use_sde=True, dry_run=False):\n",
    "    if use_goal:\n",
    "        obs_keys = ['desired_goal', 'observation']\n",
    "    else:\n",
    "        obs_keys = ['observation']\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "                    log_std_init=-3,\n",
    "                    features_extractor_class=HERCombinedExtractor,\n",
    "                    features_extractor_kwargs=dict(observation_keys=obs_keys))\n",
    "    if use_sde:\n",
    "        sde_kwargs = dict(\n",
    "                use_sde=True,\n",
    "                sde_sample_freq=4)\n",
    "    else:\n",
    "        sde_kwargs = {}\n",
    "    tensorboard_log = exp_dir if dry_run else None\n",
    "    model = PPO('MlpPolicy', env,\n",
    "                tensorboard_log=tensorboard_log,\n",
    "                # Parameters for HER\n",
    "                policy_kwargs=policy_kwargs,\n",
    "                verbose=1,\n",
    "                learning_rate=lr,\n",
    "                n_steps=1000,\n",
    "                gamma=0.99, batch_size=250, **sde_kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def env_fn_generator(diff=3, episode_length=500, relative_goal=True, reward_fn=None,\n",
    "                     termination_fn=False, save_mp4=False, save_dir='',\n",
    "                     save_freq=10, initializer=None, **env_kwargs):\n",
    "    if reward_fn is None:\n",
    "        reward_fn = training_reward4\n",
    "    else:\n",
    "        if reward_fn == 'train1':\n",
    "            reward_fn = training_reward1\n",
    "        elif reward_fn == 'train2':\n",
    "            reward_fn = training_reward2\n",
    "        elif reward_fn == 'train3':\n",
    "            reward_fn = training_reward3\n",
    "        elif reward_fn == 'train4':\n",
    "            reward_fn = training_reward4\n",
    "        elif reward_fn == 'competition':\n",
    "            reward_fn = competition_reward\n",
    "    goal = None\n",
    "    if initializer is None:\n",
    "        initializer = initializers.centered_init\n",
    "    elif initializer =='center':\n",
    "        initializer = initializers.centered_init\n",
    "    elif initializer == 'train':\n",
    "        initializer = initializers.training_init\n",
    "    elif initializer == 'fixed':\n",
    "        from trifinger_simulation.tasks.move_cube import Pose\n",
    "        import json\n",
    "        goal = Pose.from_json(json.load(open('goal.json', 'r'))).to_dict()\n",
    "        initializer = initializers.fixed_g_init(diff, goal)\n",
    "    if termination_fn:\n",
    "        termination_fn = stay_close_to_goal if diff<4 else stay_close_to_goal_level_4\n",
    "    else:\n",
    "        termination_fn = None\n",
    "\n",
    "    def env_fn():\n",
    "        env = cube_env.CubeEnv(goal, diff,\n",
    "                initializer=initializer,\n",
    "                episode_length=episode_length,\n",
    "                relative_goal=relative_goal,\n",
    "                reward_fn=reward_fn,\n",
    "                force_factor=1,\n",
    "                torque_factor=.1,\n",
    "                termination_fn=termination_fn,\n",
    "                **env_kwargs)\n",
    "        if save_mp4:\n",
    "            env = MonitorPyBulletWrapper(env, save_dir, save_freq)\n",
    "        env = FlattenGoalObs(env, ['desired_goal', 'achieved_goal', 'observation'])\n",
    "        return Monitor(env, info_keywords=('ori_err', 'pos_err'))\n",
    "    return env_fn\n",
    "\n",
    "\n",
    "def make_env_cls(diff=3, initializer='train',\n",
    "                     episode_length=500, relative_goal=True, reward_fn=None,\n",
    "                     termination_fn=False, **env_kwargs):\n",
    "    if reward_fn is None:\n",
    "        reward_fn = training_reward4\n",
    "    else:\n",
    "        if reward_fn == 'train1':\n",
    "            reward_fn = training_reward1\n",
    "        elif reward_fn == 'train2':\n",
    "            reward_fn = training_reward2\n",
    "        elif reward_fn == 'train3':\n",
    "            reward_fn = training_reward3\n",
    "        elif reward_fn == 'train4':\n",
    "            reward_fn = training_reward4\n",
    "        elif reward_fn == 'competition':\n",
    "            reward_fn = competition_reward\n",
    "    if termination_fn:\n",
    "        termination_fn = stay_close_to_goal if diff<4 else stay_close_to_goal_level_4\n",
    "    else:\n",
    "        termination_fn = None\n",
    "\n",
    "    if initializer is None:\n",
    "        initializer = initializers.centered_init\n",
    "    elif initializer =='center':\n",
    "        initializer = initializers.centered_init\n",
    "    elif initializer == 'train':\n",
    "        initializer = initializers.training_init\n",
    "    elif initializer == 'fixed':\n",
    "        from trifinger_simulation.tasks.move_cube import Pose\n",
    "        import json\n",
    "        goal = Pose.from_json(json.load(open('goal.json', 'r'))).to_dict()\n",
    "        initializer = initializers.fixed_g_init(diff, goal)\n",
    "\n",
    "    env_cls = functools.partial(cube_env.CubeEnv, cube_goal_pose=None,\n",
    "            goal_difficulty=diff,\n",
    "            initializer=initializer,\n",
    "            episode_length=episode_length,\n",
    "            relative_goal=relative_goal,\n",
    "            reward_fn=reward_fn,\n",
    "            termination_fn=termination_fn,\n",
    "            **env_kwargs)\n",
    "    return env_cls\n",
    "\n",
    "\n",
    "def train_save_model(model, eval_env, exp_dir, n_steps=1e5, reset_num_timesteps=False):\n",
    "    model.learn(n_steps, eval_env=eval_env, n_eval_episodes=5,\n",
    "                eval_freq=10000, reset_num_timesteps=False,\n",
    "                eval_log_path=exp_dir)\n",
    "    # Save the trained agent\n",
    "    model.save(osp.join(exp_dir, '{:.0e}-steps'.format(model.num_timesteps)))\n",
    "    return model\n",
    "\n",
    "\n",
    "wandb_root = '/scr-ssd/ksrini/spinningup/notebooks'\n",
    "get_save_path = lambda run: '/'.join([wandb_root] + run.config['exp_dir'].split('/')[1:])\n",
    "\n",
    "def display_video(path=None, run=None):\n",
    "    if run:\n",
    "        path = get_save_path(run.config['exp_dir'])\n",
    "    return Video(path, embed=True, width=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env_cls = make_env_cls(1, episode_length=500, reward_fn='train2',\n",
    "                       termination_fn=True, initializer='center', \n",
    "                       torque_factor=.1, force_factor=.1)\n",
    "\n",
    "wrapper = lambda env: FlattenGoalObs(ResidualPDWrapper(env), \n",
    "                                     observation_keys=['desired_goal', 'achieved_goal', 'observation'])\n",
    "\n",
    "env = make_vec_env(env_cls, n_envs=10, wrapper_class=wrapper,\n",
    "        monitor_kwargs=dict(info_keywords=('ori_err', 'pos_err')))\n",
    "\n",
    "model = make_ppo_model(500, 3e-4, None, env, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrshna\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">residual-ppo-diff1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/krshna/cvxrl\" target=\"_blank\">https://wandb.ai/krshna/cvxrl</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/krshna/cvxrl/runs/bey2mhan\" target=\"_blank\">https://wandb.ai/krshna/cvxrl/runs/bey2mhan</a><br/>\n",
       "                Run data is saved locally in <code>/scr-ssd/ksrini/benchmark-rrc/notebooks/wandb/run-20210623_081851-bey2mhan</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(bey2mhan)</h1><iframe src=\"https://wandb.ai/krshna/cvxrl/runs/bey2mhan\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2576558b38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='cvxrl', name='residual-ppo-diff1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = './data'\n",
    "hms_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "exp_name = 'ResidualPPO_rrc-diff{}'.format(1)\n",
    "exp_dir = osp.join(exp_root, exp_name, hms_time)\n",
    "os.makedirs(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./data/ResidualPPO_rrc-diff1/2021-06-23_08-19-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rrc/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 755      |\n",
      "|    ep_rew_mean     | 89.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 611      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 830         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.089975215 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | -0.00634    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.0273      |\n",
      "|    std                  | 0.0527      |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 825        |\n",
      "|    ep_rew_mean          | 171        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 552        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07743649 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.65       |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.0072     |\n",
      "|    std                  | 0.0536     |\n",
      "|    value_loss           | 49.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 807         |\n",
      "|    ep_rew_mean          | 144         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017366935 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.75        |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.000413   |\n",
      "|    std                  | 0.0543      |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 805         |\n",
      "|    ep_rew_mean          | 121         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014680845 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.88        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    std                  | 0.0544      |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 799         |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010711862 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.71        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 0.0545      |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 815         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 538         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017238492 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.14        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.0546      |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 816         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013622087 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.82        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    std                  | 0.0548      |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 821         |\n",
      "|    ep_rew_mean          | 191         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012132759 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.3         |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=410.30 +/- 565.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 410         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 792         |\n",
      "|    ep_rew_mean          | 225         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579649 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.74        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 89.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 789         |\n",
      "|    ep_rew_mean          | 237         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013728211 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.23        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 781         |\n",
      "|    ep_rew_mean          | 256         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010179812 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.61        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    std                  | 0.0552      |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 778         |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012142862 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.8         |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 0.0553      |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 754         |\n",
      "|    ep_rew_mean          | 299         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010608686 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.67        |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    std                  | 0.0555      |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 760         |\n",
      "|    ep_rew_mean          | 274         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019605184 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.01        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.0558      |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 769         |\n",
      "|    ep_rew_mean          | 254         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012600553 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.3         |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.0558      |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 794        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 170000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02604274 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.51       |\n",
      "|    explained_variance   | 0.584      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00784   |\n",
      "|    std                  | 0.0562     |\n",
      "|    value_loss           | 47.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 800         |\n",
      "|    ep_rew_mean          | 197         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023134027 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.92        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    std                  | 0.0565      |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 804         |\n",
      "|    ep_rew_mean          | 196         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013860391 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.17        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.78        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    std                  | 0.0567      |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=220.60 +/- 384.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 221         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 840         |\n",
      "|    ep_rew_mean          | 212         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018442329 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.83        |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.0569      |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 841         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017054955 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.68        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.0573      |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 855         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022304967 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.15        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.0576      |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 847         |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022077255 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.59        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    std                  | 0.0581      |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 828         |\n",
      "|    ep_rew_mean          | 234         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022912432 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.28        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.0585      |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 830         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015405876 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.4         |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    std                  | 0.0587      |\n",
      "|    value_loss           | 82.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 828         |\n",
      "|    ep_rew_mean          | 250         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020472635 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.66        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 0.059       |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 824         |\n",
      "|    ep_rew_mean          | 227         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013699718 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.52        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    std                  | 0.0593      |\n",
      "|    value_loss           | 96.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 827         |\n",
      "|    ep_rew_mean          | 205         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012795557 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.95        |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.07        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.0595      |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | 232         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018146489 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.43        |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    std                  | 0.0598      |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=317.74 +/- 230.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 318         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 804         |\n",
      "|    ep_rew_mean          | 220         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020308465 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.35        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 0.0602      |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 812         |\n",
      "|    ep_rew_mean          | 211         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032870494 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.21        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.14        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.0609      |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 822         |\n",
      "|    ep_rew_mean          | 206         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027509037 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.17        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.0615      |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 800         |\n",
      "|    ep_rew_mean          | 214         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047285914 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.41        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00683     |\n",
      "|    std                  | 0.0625      |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 789         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018754324 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.25        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.0629      |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029290557 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.4         |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.000321   |\n",
      "|    std                  | 0.0632      |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 796         |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015180449 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.27        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    std                  | 0.0632      |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 805        |\n",
      "|    ep_rew_mean          | 232        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 729        |\n",
      "|    total_timesteps      | 370000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05015875 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.36       |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.13       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    std                  | 0.0636     |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 799         |\n",
      "|    ep_rew_mean          | 237         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018092547 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.1         |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    std                  | 0.0638      |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 799         |\n",
      "|    ep_rew_mean          | 197         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021088578 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.18        |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    std                  | 0.0641      |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=190.35 +/- 259.31\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 190         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 819         |\n",
      "|    ep_rew_mean          | 213         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015401801 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.39        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.0642      |\n",
      "|    value_loss           | 9.02        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 819        |\n",
      "|    ep_rew_mean          | 211        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 816        |\n",
      "|    total_timesteps      | 410000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06961136 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.85       |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.85       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0175     |\n",
      "|    std                  | 0.0652     |\n",
      "|    value_loss           | 26.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 842          |\n",
      "|    ep_rew_mean          | 242          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 834          |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148254605 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 7.32         |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 0.0653       |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 856         |\n",
      "|    ep_rew_mean          | 254         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014388527 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.19        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 0.0656      |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 820         |\n",
      "|    ep_rew_mean          | 226         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015844416 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.73        |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    std                  | 0.0659      |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 828         |\n",
      "|    ep_rew_mean          | 212         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 891         |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039775826 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.63        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.11        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000873   |\n",
      "|    std                  | 0.0664      |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 857         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 910         |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012793073 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.06        |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.0667      |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 867         |\n",
      "|    ep_rew_mean          | 225         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 929         |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028472126 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.37        |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    std                  | 0.067       |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 877         |\n",
      "|    ep_rew_mean          | 256         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 948         |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016505938 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.05        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.0673      |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 887          |\n",
      "|    ep_rew_mean          | 234          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141714495 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 6.12         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00945     |\n",
      "|    std                  | 0.0675       |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=278.23 +/- 547.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 278         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 879         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039152734 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.45        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.00397     |\n",
      "|    std                  | 0.0678      |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 837         |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047843035 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.85        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | 0.0228      |\n",
      "|    std                  | 0.0685      |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 857         |\n",
      "|    ep_rew_mean          | 222         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1035        |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019880155 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.4         |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    std                  | 0.0686      |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 848         |\n",
      "|    ep_rew_mean          | 246         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023894828 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.85        |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.0686      |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 833        |\n",
      "|    ep_rew_mean          | 247        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 1073       |\n",
      "|    total_timesteps      | 540000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07120056 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 8.11       |\n",
      "|    explained_variance   | 0.835      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.36       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.02       |\n",
      "|    std                  | 0.0696     |\n",
      "|    value_loss           | 30.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 822         |\n",
      "|    ep_rew_mean          | 262         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1092        |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014086592 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.41        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    std                  | 0.0698      |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | 229         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1111        |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033597585 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.5         |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.07        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 814        |\n",
      "|    ep_rew_mean          | 232        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 1130       |\n",
      "|    total_timesteps      | 570000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01976363 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.21       |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.23       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.0702     |\n",
      "|    value_loss           | 14.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 838         |\n",
      "|    ep_rew_mean          | 261         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1149        |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018067488 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.39        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    std                  | 0.0706      |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 872         |\n",
      "|    ep_rew_mean          | 265         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1168        |\n",
      "|    total_timesteps      | 590000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013259399 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.82        |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.0708      |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=7.03 +/- 10.30\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 7.03        |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | 257         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013146806 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.8         |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    std                  | 0.0711      |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 885         |\n",
      "|    ep_rew_mean          | 239         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1217        |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013517764 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.75        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 0.0711      |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | 198         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1236        |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013852599 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.15        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    std                  | 0.0711      |\n",
      "|    value_loss           | 65.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 892         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1255        |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027393837 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.03        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 0.0711      |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 893        |\n",
      "|    ep_rew_mean          | 178        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 1274       |\n",
      "|    total_timesteps      | 640000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01787776 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.3        |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.33       |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0052    |\n",
      "|    std                  | 0.0716     |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 860         |\n",
      "|    ep_rew_mean          | 207         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028341854 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.31        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | 0.00886     |\n",
      "|    std                  | 0.0721      |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | 219         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1312        |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017754592 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.38        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    std                  | 0.0724      |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 813         |\n",
      "|    ep_rew_mean          | 262         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021874666 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 8.83        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.0726      |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 810         |\n",
      "|    ep_rew_mean          | 275         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021012437 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.63        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    std                  | 0.0729      |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 795         |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1369        |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015107947 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.76        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.0729      |\n",
      "|    value_loss           | 72.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=126.97 +/- 235.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 127         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 808         |\n",
      "|    ep_rew_mean          | 368         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1399        |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020130713 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.81        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    std                  | 0.0732      |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 805        |\n",
      "|    ep_rew_mean          | 389        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 1418       |\n",
      "|    total_timesteps      | 710000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01481089 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.51       |\n",
      "|    explained_variance   | 0.629      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.4       |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.00724   |\n",
      "|    std                  | 0.0731     |\n",
      "|    value_loss           | 80.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 798        |\n",
      "|    ep_rew_mean          | 379        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 1437       |\n",
      "|    total_timesteps      | 720000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05240205 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 6.17       |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.00533    |\n",
      "|    std                  | 0.0735     |\n",
      "|    value_loss           | 33.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 806         |\n",
      "|    ep_rew_mean          | 393         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1456        |\n",
      "|    total_timesteps      | 730000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026822228 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.86        |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.77        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.0021      |\n",
      "|    std                  | 0.0737      |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 829         |\n",
      "|    ep_rew_mean          | 407         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1475        |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057002485 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.64        |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    std                  | 0.0745      |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 799         |\n",
      "|    ep_rew_mean          | 357         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1494        |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023180826 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.37        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | 0.000369    |\n",
      "|    std                  | 0.0749      |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 830         |\n",
      "|    ep_rew_mean          | 435         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1513        |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016887283 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.95        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    std                  | 0.075       |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | 434         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1532        |\n",
      "|    total_timesteps      | 770000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028092708 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.19        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    std                  | 0.0753      |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 839         |\n",
      "|    ep_rew_mean          | 386         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1551        |\n",
      "|    total_timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426798 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.55        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    std                  | 0.0755      |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | 376         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1570        |\n",
      "|    total_timesteps      | 790000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555916 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 8.22        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.0758      |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=484.55 +/- 441.83\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 485         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 869         |\n",
      "|    ep_rew_mean          | 351         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1601        |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012126094 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.65        |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.88        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    std                  | 0.0758      |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 880        |\n",
      "|    ep_rew_mean          | 355        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 1620       |\n",
      "|    total_timesteps      | 810000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02149018 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 7.54       |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.4        |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 0.0759     |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 886         |\n",
      "|    ep_rew_mean          | 334         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1638        |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025946146 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.57        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    std                  | 0.0765      |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 894        |\n",
      "|    ep_rew_mean          | 310        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 1657       |\n",
      "|    total_timesteps      | 830000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01578966 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.61       |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.51       |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00162   |\n",
      "|    std                  | 0.077      |\n",
      "|    value_loss           | 21.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 932         |\n",
      "|    ep_rew_mean          | 328         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1676        |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045288067 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.96        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    std                  | 0.0776      |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 893         |\n",
      "|    ep_rew_mean          | 294         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 850000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016753439 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.83        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    std                  | 0.0778      |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 862         |\n",
      "|    ep_rew_mean          | 225         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1714        |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706173 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.03        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    std                  | 0.0777      |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 837         |\n",
      "|    ep_rew_mean          | 220         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1734        |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018677304 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.55        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 0.0777      |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | 270         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1752        |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018909479 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.6         |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    std                  | 0.078       |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 844         |\n",
      "|    ep_rew_mean          | 327         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1772        |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017356109 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.52        |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    std                  | 0.0783      |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=105.02 +/- 210.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 105         |\n",
      "|    success_rate         | 0           |\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 845         |\n",
      "|    ep_rew_mean          | 312         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1802        |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016798738 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.25        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000384   |\n",
      "|    std                  | 0.0788      |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 797         |\n",
      "|    ep_rew_mean          | 325         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1821        |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013522163 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.25        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    std                  | 0.0788      |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 790         |\n",
      "|    ep_rew_mean          | 295         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1840        |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018520312 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.48        |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    std                  | 0.0788      |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 815         |\n",
      "|    ep_rew_mean          | 283         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1859        |\n",
      "|    total_timesteps      | 930000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014399362 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.02        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.0789      |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 837         |\n",
      "|    ep_rew_mean          | 328         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1878        |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013335042 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 6.25        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.48        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.0791      |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 850         |\n",
      "|    ep_rew_mean          | 323         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1897        |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016517065 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 7.19        |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    std                  | 0.0793      |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 854        |\n",
      "|    ep_rew_mean          | 342        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 1916       |\n",
      "|    total_timesteps      | 960000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01758961 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.94       |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.86       |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 0.0793     |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logger = configure(exp_dir, ['stdout', 'wandb'])\n",
    "model.set_logger(logger)\n",
    "eval_env = make_vec_env(env_cls, n_envs=1, wrapper_class=wrapper,\n",
    "        monitor_kwargs=dict(info_keywords=('ori_err', 'pos_err')))\n",
    "model = train_save_model(model, eval_env, exp_dir, 1e6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
