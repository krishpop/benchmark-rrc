{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a37f0de-9c9d-41d0-8a4a-a04ffcba13ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_38' (/scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n",
      "PyTorch version 1.10.0+cu102\n",
      "Device count 1\n",
      "/scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/src/gymtorch\n",
      "Using /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions/py38_cu102 as PyTorch extensions root...\n",
      "Emitting ninja build file /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions/py38_cu102/gymtorch/build.ninja...\n",
      "Building extension module gymtorch...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module gymtorch...\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "from isaacgym.torch_utils import to_torch\n",
    "\n",
    "from rrc.env import fop, make_env\n",
    "from trifinger_simulation.tasks.move_cube import Pose\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cc6c82-fd8d-4925-aaec-120cc744f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb on\n",
    "env = make_env.env_fn_generator(diff=1, env_cls='robot_wrench_env', flatten_goal=True,\n",
    "                               use_traj_opt=False)()\n",
    "obs = env.reset()\n",
    "obs, r, d ,i = env.step(np.zeros(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b635ed-0a18-4368-99cc-d02907b75802",
   "metadata": {},
   "outputs": [],
   "source": [
    "acscale = np.concatenate([env.force_factor, [env.torque_factor]*3])\n",
    "cp_wf = env.get_cp_wf_list(None, obj_pose=Pose(obs['achieved_goal'][:3], obs['achieved_goal'][3:]), use_actual_cp=True)\n",
    "cp_list = []\n",
    "for cpf in cp_wf:\n",
    "    if cpf is None:\n",
    "        cp_list.append(np.array([0]*6 + [1]))\n",
    "    else:\n",
    "        cp_list.append(np.concatenate(cpf))\n",
    "cp_v = np.array(cp_list)\n",
    "n = 1024\n",
    "cp_list = np.array([cp_v.flatten() for i in range(n)]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7dd9b1d-c98d-41a1-b8bc-d313bdb22d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.43550523e-02,  2.75191342e-03,  3.69284796e-02,\n",
       "         3.18449096e-06,  2.50979308e-06,  7.85395725e-01,\n",
       "        -6.18993987e-01],\n",
       "       [-5.79314364e-02, -3.72151363e-02,  3.58668177e-02,\n",
       "        -6.24734813e-03,  7.40228387e-04,  9.93033843e-01,\n",
       "         1.17661418e-01],\n",
       "       [-1.21413341e-01, -2.33746197e-02,  3.95698661e-02,\n",
       "         2.82240769e-03,  2.13487065e-02,  1.31034274e-01,\n",
       "        -9.91143928e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f404237-df2c-4132-b327-d6ac16210944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/torch_utils.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jul  8 2020 18:24:53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  6.8587e-01, -2.5774e-01,\n",
       "         -6.8055e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  3.5177e-01,  9.3609e-01,\n",
       "         -1.2811e-07,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  6.3705e-01, -2.3939e-01,\n",
       "          7.3270e-01,  0.0000e+00,  0.0000e+00,  1.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.4986e-02, -3.8203e-02,\n",
       "         -7.1183e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0852e-02, -1.1594e-02,\n",
       "         -6.0992e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4463e-02, -4.2034e-03,\n",
       "         -6.6116e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.fop.get_grasp_matrix(to_torch(cp_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51a2fad-435f-4d9c-872b-1723aad3750c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \"\"\"\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# handle negative axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0mnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asanyarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "%time x = apply(cvxlayer.get_grasp_matrix, to_torch(cp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2abd9d9a-e58d-4907-80c1-e12704654f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/user/18784/ipykernel_522349/3124899779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcp_list_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_list_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \"\"\"\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# handle negative axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0mnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/scr1/.pyenv/versions/rlgpu/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m(643)\u001b[0;36m__array__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    641 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    642 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 643 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    644 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    645 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "cp_list_t = to_torch(cp_list)\n",
    "np.apply_along_axis(torch.is_tensor, 1, cp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd604c6d-4503-4bb8-932e-c9e99dbaed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvxlayer = fop.BatchForceOptProblem(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2d8a034-f740-450b-9b89-32ec390ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_wrench_t = torch.tensor([env.action_space.sample().astype('float32') * acscale for _ in range(n)], dtype=torch.float).to(cvxlayer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d36f1b1b-0be1-4f21-8c6a-37b730dbbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_list_t = torch.as_tensor(cp_list).to(cvxlayer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "895f63c5-1d58-4320-834c-774e5de05d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.12 s, sys: 1.34 s, total: 10.5 s\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "lamb = cvxlayer(des_wrench_t, cp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a9a177-5f4e-4368-af3f-b2c2a89dfbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948c7e52-2427-4a76-bd15-b3b347512d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_wf = [(np.array([-0.04190509,  0.00978352,  0.03772653]),\n",
    "np.array([ 7.71566743e-06,  6.29104656e-06,  7.75028033e-01, -6.31926853e-01])),\n",
    " (np.array([-0.013862  , -0.0309698 ,  0.03706019]),\n",
    "  np.array([ 2.23345856e-05, -2.27164750e-06,  9.94867341e-01,  1.01187815e-01])),\n",
    " (np.array([-0.07742409, -0.01736268,  0.03893098]),\n",
    "  np.array([-2.27164750e-06, -2.23345856e-05,  1.01187815e-01, -9.94867341e-01]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de6dded-85f6-47b1-b3a7-04c99d086c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.concatenate(cpwf) for cpwf in cp_wf]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33404042-cdb4-46c3-90c7-04660b185ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_o_2_wf = Rotation.from_quat(obs['achieved_goal'][3:])\n",
    "cp_list = []\n",
    "for cp in cp_of:\n",
    "    if cp is not None:\n",
    "        c_pos, c_ori = cp\n",
    "        c_pos_wf = R_o_2_wf.as_matrix() @ c_pos\n",
    "        c_ori_wf = R_o_2_wf * Rotation.from_quat(c_ori)\n",
    "        c_ori_wf = c_ori_wf.as_quat()\n",
    "        cp_list.append((c_pos_wf, c_ori_wf))\n",
    "    else:\n",
    "        cp_list.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a589c530-c352-449c-be8b-13c325ce7ba4",
   "metadata": {},
   "source": [
    "```python\n",
    "        if use_actual_cp and self._current_contact_pos is not None:\n",
    "            R_o_2_wf = Rotation.from_quat(obj_pose.orientation)\n",
    "            R_w_2_of = R_o_2_wf.inv().as_matrix()\n",
    "            flip_z = Rotation.from_rotvec([0, 0, np.pi]).as_matrix()\n",
    "            for pos_wf, ori in zip(\n",
    "                self._current_contact_pos, self._current_contact_ori\n",
    "            ):\n",
    "                if ori is None:\n",
    "                    cp_list.append(None)\n",
    "                else:\n",
    "                    cp_quat = Rotation.from_matrix(R_w_2_of @ flip_z @ ori).as_quat()\n",
    "                    R = Rotation.from_quat(obj_pose.orientation) * Rotation.from_quat(\n",
    "                        cp_quat\n",
    "                    )\n",
    "                    quat_cp_2_w = R.as_quat()\n",
    "                    cp_list.append((pos_wf, quat_cp_2_w))\n",
    "        else:\n",
    "            R_o_2_wf = Rotation.from_quat(obj_pose.orientation)\n",
    "            for cp_param in cp_params:\n",
    "                if cp_param is not None:\n",
    "                    cp_of = c_utils.get_cp_of_from_cp_param(cp_param)\n",
    "                    pos_wf = c_utils.get_wf_from_of(cp_of.pos_of, obj_pose)\n",
    "                    R = R_o_2_wf * Rotation.from_quat(cp_of.quat_of)\n",
    "                    quat_cp_2_w = R.as_quat()\n",
    "                    # pos_wf = R_o_2_wf.as_matrix() @ cp_of.pos_of\n",
    "                    cp_list.append((pos_wf, quat_cp_2_w))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39699a02-e220-4826-8f1a-b4d389bcd0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-0.04189374,  0.00980485, -0.59420026]),\n",
       "  array([ 7.71566743e-06,  6.29104656e-06,  7.75028033e-01, -6.31926853e-01])),\n",
       " (array([-0.01385064, -0.03094847, -0.5948666 ]),\n",
       "  array([ 2.23345856e-05, -2.27164750e-06,  9.94867341e-01,  1.01187815e-01])),\n",
       " (array([-0.07741273, -0.01734135, -0.5929958 ]),\n",
       "  array([-2.27164750e-06, -2.23345856e-05,  1.01187815e-01, -9.94867341e-01]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89da7c98-ced2-418b-b76c-af5070b9e824",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 21504 into shape (3,7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/user/18784/ipykernel_86802/2025040369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchForceOptProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grasp_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scr-ssd/ksrini/benchmark-rrc/rrc/env/fop.py\u001b[0m in \u001b[0;36mget_grasp_matrix\u001b[0;34m(self, cp_list)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcp_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# make cp_list an np.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mcp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcp_wf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcp_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcp_wf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcp_wf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 21504 into shape (3,7)"
     ]
    }
   ],
   "source": [
    "prob = fop.BatchForceOptProblem()\n",
    "G2 = prob.get_grasp_matrix(cp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec8927-1b06-4d22-a032-8fab0c1aad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = obs['achieved_goal']\n",
    "obj_pose = np.asarray([op for _ in range(10)])\n",
    "cp_wf = [cp_wf for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b7647d7-cd8d-4a4f-b8b3-7a6e506b78d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.02326169384260848, 0.06405488240915017, 0.04545479707254271],\n",
       " [0.029158603370715852, -0.018415214062422455, 0.04492667906354321],\n",
       " [-0.04664714912920895, 0.0026628426942095426, 0.0449847631644697]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.pinocchio_utils.forward_kinematics(env.unwrapped.prev_observation['observation']['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e8c8ab6-1db1-463a-a1f7-1029860dd150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.02032874, 0.05563401, 0.85349421]),\n",
       " array([ 0.02290265, -0.01268787,  0.85237941]),\n",
       " array([-0.03887879,  0.00640975,  0.85346884])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in cp_wf[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7c9836-7a64-4631-88e3-af67da4697ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d072d3ac-89bb-480f-980a-7c0061d08ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import torch\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "n, m = 2, 3\n",
    "x = cp.Variable(n)\n",
    "A = cp.Parameter((m, n))\n",
    "b = cp.Parameter(m)\n",
    "constraints = [x >= 0]\n",
    "objective = cp.Minimize(0.5 * cp.pnorm(A @ x - b, p=1))\n",
    "problem = cp.Problem(objective, constraints)\n",
    "assert problem.is_dpp()\n",
    "\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[A, b], variables=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fad72e-7663-4ef9-ab63-892654567beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 3.73 s, total: 21.6 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "bs = 2048\n",
    "A_tch = torch.randn(bs, m, n, requires_grad=True)\n",
    "b_tch = torch.randn(bs, m, requires_grad=True)\n",
    "\n",
    "# solve the problem\n",
    "solution, = cvxpylayer(A_tch, b_tch)\n",
    "\n",
    "# compute the gradient of the sum of the solution with respect to A, b\n",
    "solution.sum().backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgpu",
   "language": "python",
   "name": "rlgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
